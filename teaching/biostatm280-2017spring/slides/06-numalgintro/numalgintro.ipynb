{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical linear algebra: introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Topics in numerical algebra: \n",
    "    - BLAS  \n",
    "    - solve linear equations $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$\n",
    "    - regression computations $\\mathbf{X}^T \\mathbf{X} \\beta = \\mathbf{X}^T \\mathbf{y}$  \n",
    "    - eigen-problems $\\mathbf{A} \\mathbf{x} = \\lambda \\mathbf{x}$  \n",
    "    - generalized eigen-problems $\\mathbf{A} \\mathbf{x} = \\lambda \\mathbf{B} \\mathbf{x}$  \n",
    "    - singular value decompositions $\\mathbf{A} = \\mathbf{U} \\Sigma \\mathbf{V}^T$  \n",
    "    - iterative methods  \n",
    "\n",
    "* Except for the iterative methods, most of these numerical linear algebra tasks are implemented in the BLAS and LAPACK libraries. They form the **building blocks** of most statistical computing tasks (optimization, MCMC).\n",
    "\n",
    "* Our major **goal** (or learning objectives) is to  \n",
    "    0. know the computational cost (flop count) of each task\n",
    "    0. be familiar with the BLAS and LAPACK functions (what they do)  \n",
    "    0. do **not** re-invent wheels by implementing these dense linear algebra subroutines by yourself  \n",
    "    0. understand the need for iterative methods  \n",
    "    0. apply appropriate numerical algebra tools to various statistical problems \n",
    "\n",
    "* All high-level languages (R, Matlab, Julia) call BLAS and LAPACK for numerical linear algebra. \n",
    "    - Julia offers more flexibility by exposing interfaces to many BLAS/LAPACK subroutines directly. See [documentation](https://docs.julialang.org/en/stable/stdlib/linalg/?highlight=blas#module-Base.LinAlg.BLAS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLAS\n",
    "\n",
    "* BLAS stands for _basic linear algebra subprograms_. \n",
    "\n",
    "* See [netlib](http://www.netlib.org/blas/) for a complete list of standardized BLAS functions.\n",
    "\n",
    "* There are many implementations of BLAS. \n",
    "    - [Netlib](http://www.netlib.org/blas/) provides a reference implementation  \n",
    "    - Matlab uses Intel's [MKL](https://software.intel.com/en-us/node/520724) (mathematical kernel libaries)  \n",
    "    - Julia uses [OpenBLAS](https://github.com/xianyi/OpenBLAS)\n",
    "\n",
    "* There are 3 levels of BLAS functions.\n",
    "    - Level 1: vector-vector operation\n",
    "    - Level 2: matrix-vector operation\n",
    "    - Level 3: matrix-matrix operation\n",
    "\n",
    "| Level | Example Operation                      | Name        | Dimension                                 | Flops |\n",
    "|-------|----------------------------------------|-------------|-------------------------------------------|-------|\n",
    "| 1     | $\\alpha \\gets \\mathbf{x}^T \\mathbf{y}$ | dot product | $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$ | $2n$  |\n",
    "|       | $\\mathbf{y} \\gets \\mathbf{y} + \\alpha \\mathbf{x}$ |  axpy           |  $\\alpha \\in \\mathbb{R}$, $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$ |  $2n$    |\n",
    "| 2     | $\\mathbf{y} \\gets \\mathbf{y} + \\mathbf{A} \\mathbf{x}$ |  gaxpy           |  $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, $\\mathbf{x} \\in \\mathbb{R}^n$, $\\mathbf{y} \\in \\mathbb{R}^m$                                     |  $2mn$     |\n",
    "|       | $\\mathbf{A} \\gets \\mathbf{A} + \\mathbf{y} \\mathbf{x}^T$ | rank one update            |    $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, $\\mathbf{x} \\in \\mathbb{R}^n$, $\\mathbf{y} \\in \\mathbb{R}^m$                                       | $2mn$      |\n",
    "| 3     | $\\mathbf{C} \\gets \\mathbf{C} + \\mathbf{A} \\mathbf{B}$                                       |  matrix multiplication           |  $\\mathbf{A} \\in \\mathbb{R}^{m \\times p}$, $\\mathbf{B} \\in \\mathbb{R}^{p \\times n}$, $\\mathbf{C} \\in \\mathbb{R}^{m \\times n}$                                         | $2mnp$      |\n",
    "\n",
    "* Typical BLAS functions support single precision (S), double precision (D), complex (C), and double complex (Z). \n",
    "\n",
    "* Some operations appear as level-3 but indeed are level-2.  \n",
    "    - A common operation in statistics is column scaling or row scaling\n",
    "    $$\n",
    "    \\begin{eqnarray*}\n",
    "        \\mathbf{A} &=& \\mathbf{A} \\mathbf{D} \\quad \\text{(column scaling)} \\\\\n",
    "        \\mathbf{A} &=& \\mathbf{D} \\mathbf{A} \\quad \\text{(row scaling)}\n",
    "    \\end{eqnarray*}\n",
    "    $$\n",
    "    where $\\mathbf{D}$ is diagonal.  \n",
    "    - These are essentially level-2 operation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  30.52 MiB\n",
       "  allocs estimate:  2\n",
       "  --------------\n",
       "  minimum time:     101.964 ms (3.48% GC)\n",
       "  median time:      103.480 ms (3.55% GC)\n",
       "  mean time:        105.687 ms (4.21% GC)\n",
       "  maximum time:     143.148 ms (28.83% GC)\n",
       "  --------------\n",
       "  samples:          48\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "n = 2000\n",
    "\n",
    "A = rand(n, n)\n",
    "d = rand(n)  # d vector\n",
    "D = diagm(d) # diagonal matrix with d as diagonal\n",
    "\n",
    "# this is calling BLAS routine for matrix multiplication\n",
    "@benchmark A * D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mWARNING: scale(A::AbstractMatrix,x::AbstractVector) is deprecated, use A * Diagonal(x) instead.\u001b[0m\n",
      " in depwarn(::String, ::Symbol) at ./deprecated.jl:64\n",
      " in scale(::Array{Float64,2}, ::Array{Float64,1}) at ./deprecated.jl:50\n",
      " in ##core#278() at /Users/huazhou/.julia/v0.5/BenchmarkTools/src/execution.jl:290\n",
      " in ##sample#279(::BenchmarkTools.Parameters) at /Users/huazhou/.julia/v0.5/BenchmarkTools/src/execution.jl:296\n",
      " in #_run#2(::Bool, ::String, ::Array{Any,1}, ::Function, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#277\")}, ::BenchmarkTools.Parameters) at /Users/huazhou/.julia/v0.5/BenchmarkTools/src/execution.jl:324\n",
      " in (::BenchmarkTools.#kw##_run)(::Array{Any,1}, ::BenchmarkTools.#_run, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#277\")}, ::BenchmarkTools.Parameters) at ./<missing>:0\n",
      " in anonymous at ./<missing>:?\n",
      " in #run_result#16(::Array{Any,1}, ::Function, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#277\")}, ::BenchmarkTools.Parameters) at /Users/huazhou/.julia/v0.5/BenchmarkTools/src/execution.jl:40\n",
      " in (::BenchmarkTools.#kw##run_result)(::Array{Any,1}, ::BenchmarkTools.#run_result, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#277\")}, ::BenchmarkTools.Parameters) at ./<missing>:0\n",
      " in #run#17(::Array{Any,1}, ::Function, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#277\")}, ::BenchmarkTools.Parameters) at /Users/huazhou/.julia/v0.5/BenchmarkTools/src/execution.jl:43\n",
      " in (::Base.#kw##run)(::Array{Any,1}, ::Base.#run, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#277\")}, ::BenchmarkTools.Parameters) at ./<missing>:0\n",
      " in warmup(::BenchmarkTools.Benchmark{Symbol(\"##benchmark#277\")}) at /Users/huazhou/.julia/v0.5/BenchmarkTools/src/execution.jl:78\n",
      " in include_string(::String, ::String) at ./loading.jl:441\n",
      " in execute_request(::ZMQ.Socket, ::IJulia.Msg) at /Users/huazhou/.julia/v0.5/IJulia/src/execute_request.jl:157\n",
      " in eventloop(::ZMQ.Socket) at /Users/huazhou/.julia/v0.5/IJulia/src/eventloop.jl:8\n",
      " in (::IJulia.##13#19)() at ./task.jl:360\n",
      "while loading In[2], in expression starting on line 208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  30.53 MiB\n",
       "  allocs estimate:  68\n",
       "  --------------\n",
       "  minimum time:     8.908 ms (2.80% GC)\n",
       "  median time:      11.488 ms (31.38% GC)\n",
       "  mean time:        11.722 ms (31.10% GC)\n",
       "  maximum time:     57.167 ms (84.93% GC)\n",
       "  --------------\n",
       "  samples:          426\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columnwise scaling\n",
    "@benchmark scale(A, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  30.52 MiB\n",
       "  allocs estimate:  3\n",
       "  --------------\n",
       "  minimum time:     8.430 ms (2.81% GC)\n",
       "  median time:      10.937 ms (31.55% GC)\n",
       "  mean time:        11.139 ms (31.97% GC)\n",
       "  maximum time:     56.490 ms (85.42% GC)\n",
       "  --------------\n",
       "  samples:          448\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way for columnwise scaling\n",
    "@benchmark A * Diagonal(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory hierarchy and level-3 fraction\n",
    "\n",
    "> Key to high performance is effective use of memory hierarchy. True on all architectures.\n",
    "\n",
    "* Flop count is not the sole determinant of algorithm efficiency. Another important factor is data movement through the memory hierarchy.\n",
    "\n",
    "<img src=\"http://tssdr1.thessdreview1.netdna-cdn.com/wp-content/uploads/2013/10/Base-Open.png\" width=\"400\" align=\"center\">\n",
    "\n",
    "<img src=\"http://hothardware.com/ContentImages/NewsItem/34743/content/Intel-Skylake-Graphics-Gen-9-Block-Diag.jpg\" width=\"400\" align=\"center\">\n",
    "\n",
    "<img src=\"http://images.bit-tech.net/content_images/2007/11/the_secrets_of_pc_memory_part_1/hei.png\" width=\"400\" align=\"center\">\n",
    "\n",
    "* For example, Xeon X5650 CPU has a theoretical throughput of 128 DP GFLOPS but a max memory bandwidth of 32GB/s.  \n",
    "\n",
    "* Can we keep CPU cores busy with enough deliveries of matrix data and ship the results to memory fast enough to avoid backlog?  \n",
    "Answer: use **high-level BLAS** as much as possible.\n",
    "\n",
    "| BLAS                                                           | Dimension                                                                           | Mem. Refs. | Flops  | Ratio |\n",
    "|----------------------------------------------------------------|-------------------------------------------------------------------------------------|------------|--------|-------|\n",
    "| Level 1: $\\mathbf{y} \\gets \\mathbf{y} + \\alpha \\mathbf{x}$     | $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$                                           | $3n$       | $2n$   | 3:2   |\n",
    "| Level 2: $\\mathbf{y} \\gets \\mathbf{y} + \\mathbf{A} \\mathbf{x}$ | $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$, $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ | $n^2$      | $2n^2$ | 1:2   |\n",
    "| Level 3: $\\mathbf{C} \\gets \\mathbf{C} + \\mathbf{A} \\mathbf{B}$ | $\\mathbf{A}, \\mathbf{B}, \\mathbf{C} \\in\\mathbb{R}^{n \\times n}$                    | $4n^2$     | $2n^3$ | 2:n |  \n",
    "\n",
    "* Higher level BLAS (3 or 2) make more effective use of arithmetic logic units (ALU) by keeping them busy. **Surface-to-volume** effect.  \n",
    "See [Dongarra slides](https://www.samsi.info/wp-content/uploads/2017/02/SAMSI-0217_Dongarra.pdf).\n",
    "\n",
    "<img src=\"./blas_throughput.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "* A distinction between LAPACK and LINPACK (older version of R uses LINPACK) is that LAPACK makes use of higher level BLAS as much as possible (usually by smart partitioning) to increase the so-called **level-3 fraction**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of data layout\n",
    "\n",
    "* Data layout in memory affects algorithmic efficiency too. It is much faster to move chunks of data in memory than retrieving/writing scattered data.\n",
    "\n",
    "* Storage mode: **column-major** (Fortran, Matlab, R, Julia) vs **row-major** (C/C++).\n",
    "\n",
    "* **Cache line** is the minimum amount of cache which can be loaded and stored to memory.\n",
    "    - x86 CPUs: 64 bytes  \n",
    "    - ARM CPUS: 32 bytes\n",
    "\n",
    "<img src=\"https://patterns.eecs.berkeley.edu/wordpress/wp-content/uploads/2013/04/dense02.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "* Accessing column-major stored matrix by rows causes lots of **cache misses**.\n",
    "\n",
    "* Take matrix multiplication as an example \n",
    "$$ \n",
    "\\mathbf{C} \\gets \\mathbf{C} + \\mathbf{A} \\mathbf{B}, \\quad \\mathbf{A} \\in \\mathbb{R}^{m \\times p}, \\mathbf{B} \\in \\mathbb{R}^{p \\times n}, \\mathbf{C} \\in \\mathbb{R}^{m \\times n}.\n",
    "$$\n",
    "Assume the storage is column-major, such as in Julia. There are 6 variants of the algorithms according to the order in the triple loops. \n",
    "    - `jki` or `kji` looping:\n",
    "        ```julia\n",
    "        for i = 1:m\n",
    "            C[i, j] = C[i, j] + A[i, k] * B[k, j]\n",
    "        end\n",
    "        ```  \n",
    "    - `ikj` or `kij` looping:\n",
    "        ```julia\n",
    "        for j = 1:n\n",
    "            C[i, j] = C[i, j] + A[i, k] * B[k, j]\n",
    "        end\n",
    "        ```  \n",
    "    - `ijk` or `jik` looping:\n",
    "        ```julia\n",
    "        for k = 1:p\n",
    "            C[i, j] = C[i, j] + A[i, k] * B[k, j]\n",
    "        end\n",
    "        ```\n",
    "* We pay attention to the innermost loop, where the vector calculation occurs. The associated **stride** when accessing the three matrices in memory (assuming column-major storage) is  \n",
    "\n",
    "| Variant        | A Stride | B Stride | C Stride |\n",
    "|----------------|----------|----------|----------|\n",
    "| $jki$ or $kji$ | Unit     | 0        | Unit     |\n",
    "| $ikj$ or $kij$ | 0        | Non-Unit | Non-Unit |\n",
    "| $ijk$ or $jik$ | Non-Unit | Unit     | 0        |       \n",
    "Apparently the variants $jki$ or $kji$ are preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function matmul_by_loop!(A::Matrix, B::Matrix, C::Matrix, order::String)\n",
    "    \n",
    "    m = size(A, 1)\n",
    "    p = size(A, 2)\n",
    "    n = size(B, 2)\n",
    "    \n",
    "    if order == \"jki\"\n",
    "        for j = 1:n, k = 1:p, i = 1:m\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if order == \"kji\"\n",
    "        for k = 1:p, j = 1:n, i = 1:m\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if order == \"ikj\"\n",
    "        for i = 1:m, k = 1:p, j = 1:n\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if order == \"kij\"\n",
    "        for k = 1:p, i = 1:m, j = 1:n\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if order == \"ijk\"\n",
    "        for i = 1:m, j = 1:n, k = 1:p\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if order == \"jik\"\n",
    "        for j = 1:n, i = 1:m, k = 1:p\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "srand(123)\n",
    "m, n, p = 2000, 100, 2000\n",
    "A = rand(m, n)\n",
    "B = rand(n, p)\n",
    "C = zeros(m, p);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $jki$ and $kji$ looping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     429.100 ms (0.00% GC)\n",
       "  median time:      442.814 ms (0.00% GC)\n",
       "  mean time:        444.246 ms (0.00% GC)\n",
       "  maximum time:     459.781 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          12\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(C, 0.0)\n",
    "@benchmark matmul_by_loop!(A, B, C, \"jki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     522.318 ms (0.00% GC)\n",
       "  median time:      548.960 ms (0.00% GC)\n",
       "  mean time:        543.765 ms (0.00% GC)\n",
       "  maximum time:     556.943 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(C, 0.0)\n",
    "@benchmark matmul_by_loop!(A, B, C, \"kji\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ikj$ and $kij$ looping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     2.658 s (0.00% GC)\n",
       "  median time:      2.769 s (0.00% GC)\n",
       "  mean time:        2.769 s (0.00% GC)\n",
       "  maximum time:     2.880 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          2\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(C, 0.0)\n",
    "@benchmark matmul_by_loop!(A, B, C, \"ikj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     2.431 s (0.00% GC)\n",
       "  median time:      2.744 s (0.00% GC)\n",
       "  mean time:        2.744 s (0.00% GC)\n",
       "  maximum time:     3.056 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          2\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(C, 0.0)\n",
    "@benchmark matmul_by_loop!(A, B, C, \"kij\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ijk$ and $jik$ looping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     996.499 ms (0.00% GC)\n",
       "  median time:      1.006 s (0.00% GC)\n",
       "  mean time:        1.012 s (0.00% GC)\n",
       "  maximum time:     1.031 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(C, 0.0)\n",
    "@benchmark matmul_by_loop!(A, B, C, \"ijk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     1.004 s (0.00% GC)\n",
       "  median time:      1.033 s (0.00% GC)\n",
       "  mean time:        1.091 s (0.00% GC)\n",
       "  maximum time:     1.248 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(C, 0.0)\n",
    "@benchmark matmul_by_loop!(A, B, C, \"ijk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Julia wrapper of BLAS function. We see BLAS library wins hands down (multi-threading, Strassen algorithm, higher level-3 fraction by block outer product)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     4.844 ms (0.00% GC)\n",
       "  median time:      5.224 ms (0.00% GC)\n",
       "  mean time:        5.436 ms (0.00% GC)\n",
       "  maximum time:     10.025 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          914\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(C, 0.0)\n",
    "@benchmark Base.LinAlg.BLAS.gemm!('N', 'N', 1.0, A, B, 1.0, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To appreciate the efforts in an optimized BLAS implementation such as OpenBLAS (evolved from GotoBLAS), see the [Quora question](https://www.quora.com/What-algorithm-does-BLAS-use-for-matrix-multiplication-Of-all-the-considerations-e-g-cache-popular-instruction-sets-Big-O-etc-which-one-turned-out-to-be-the-primary-bottleneck), especially the [video](https://youtu.be/JzNpKDW07rw). Bottomline is \n",
    "\n",
    "> Make friends with (good implementations of) BLAS/LAPACK and use them as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoid memory allocation: some examples\n",
    "\n",
    "* Transposing matrix is an expensive memory operation.  \n",
    "    - In R, the command \n",
    "        ```R\n",
    "        t(A) %*% x\n",
    "        ```\n",
    "    will first transpose `A` then perform matrix multiplication, causing unnecessary memory allocation\n",
    "    - Julia is smart to avoid transposing matrix if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.94 KiB\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     92.976 μs (0.00% GC)\n",
       "  median time:      143.767 μs (0.00% GC)\n",
       "  mean time:        229.011 μs (0.00% GC)\n",
       "  maximum time:     1.740 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srand(123)\n",
    "\n",
    "n = 1000\n",
    "A = rand(n, n)\n",
    "x = rand(n)\n",
    "\n",
    "# dispatch to At_mul_B (and then to BLAS)\n",
    "# does *not* actually transpose the matrix\n",
    "@benchmark A' * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.94 KiB\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     94.267 μs (0.00% GC)\n",
       "  median time:      129.143 μs (0.00% GC)\n",
       "  mean time:        150.209 μs (0.00% GC)\n",
       "  maximum time:     889.597 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dispatch to BLAS\n",
    "@benchmark At_mul_B(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.64 MiB\n",
       "  allocs estimate:  3\n",
       "  --------------\n",
       "  minimum time:     2.995 ms (0.00% GC)\n",
       "  median time:      3.702 ms (0.00% GC)\n",
       "  mean time:        4.038 ms (21.29% GC)\n",
       "  maximum time:     9.451 ms (39.54% GC)\n",
       "  --------------\n",
       "  samples:          1225\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's force transpose\n",
    "@benchmark transpose(A) * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Broadcasting](https://docs.julialang.org/en/stable/manual/functions/#dot-syntax-for-vectorizing-functions) in Julia achieves vectorized code without creating intermediate arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  22.89 MiB\n",
       "  allocs estimate:  10\n",
       "  --------------\n",
       "  minimum time:     16.330 ms (9.89% GC)\n",
       "  median time:      19.290 ms (10.55% GC)\n",
       "  mean time:        19.408 ms (10.62% GC)\n",
       "  maximum time:     30.123 ms (12.41% GC)\n",
       "  --------------\n",
       "  samples:          258\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srand(123)\n",
    "X, Y = rand(1000,1000), rand(1000,1000)\n",
    "\n",
    "# two temporary arrays are created\n",
    "@benchmark max(abs(X), abs(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.63 MiB\n",
       "  allocs estimate:  37\n",
       "  --------------\n",
       "  minimum time:     2.766 ms (0.00% GC)\n",
       "  median time:      3.613 ms (0.00% GC)\n",
       "  mean time:        4.419 ms (22.56% GC)\n",
       "  maximum time:     10.487 ms (38.26% GC)\n",
       "  --------------\n",
       "  samples:          1125\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no temporary arrays created\n",
    "@benchmark max.(abs.(X), abs.(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  96 bytes\n",
       "  allocs estimate:  3\n",
       "  --------------\n",
       "  minimum time:     1.668 ms (0.00% GC)\n",
       "  median time:      1.879 ms (0.00% GC)\n",
       "  mean time:        1.995 ms (0.00% GC)\n",
       "  maximum time:     5.185 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          2473\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no memory allocation at all!\n",
    "Z = zeros(X)\n",
    "@benchmark Z .= max.(abs.(X), abs.(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [View](https://docs.julialang.org/en/stable/stdlib/arrays/#Base.view) avoids creating extra copy of matrix data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  488.47 KiB\n",
       "  allocs estimate:  5\n",
       "  --------------\n",
       "  minimum time:     62.532 μs (0.00% GC)\n",
       "  median time:      237.506 μs (0.00% GC)\n",
       "  mean time:        255.955 μs (14.62% GC)\n",
       "  maximum time:     4.642 ms (82.11% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srand(123)\n",
    "A = randn(1000, 1000)\n",
    "\n",
    "# sum entries in a sub-matrix\n",
    "@benchmark sum(A[1:2:500, 1:2:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  256 bytes\n",
       "  allocs estimate:  7\n",
       "  --------------\n",
       "  minimum time:     77.294 μs (0.00% GC)\n",
       "  median time:      84.070 μs (0.00% GC)\n",
       "  mean time:        89.548 μs (0.00% GC)\n",
       "  maximum time:     353.716 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view avoids creating a separate sub-matrix\n",
    "@benchmark sum(@view A[1:2:500, 1:2:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Julia 0.6 adds the [`@views`](https://docs.julialang.org/en/latest/manual/performance-tips.html#Consider-using-views-for-slices-1) macro, which can be useful in [some operations](https://discourse.julialang.org/t/why-is-a-manual-in-place-addition-so-much-faster-than-and-on-range-indexed-arrays/3302)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.2",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "103px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
